{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c0a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1a9a240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3bfc7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3c39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41c4dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "7566443363 (Mobile)\n",
      "rohitagr06@gmail.com\n",
      "www.linkedin.com/in/rohitagr06\n",
      "(LinkedIn)\n",
      "Top Skills\n",
      "Artificial Intelligence (AI)\n",
      "AI Agents\n",
      "Model Management\n",
      "Languages\n",
      "Hindi\n",
      "English\n",
      "Certifications\n",
      "PGDDS Course 1&2\n",
      "Teradata 14 Certified Professional\n",
      "AWS Technical Professional\n",
      "PGDDS Course 3 (Predictive\n",
      "Analytics 1)\n",
      "Rohit Agrawal\n",
      "Senior Software Engineer at OakNorth | Python Developer | Azure\n",
      "cloud | Microservices\n",
      "Hyderabad, Telangana, India\n",
      "Summary\n",
      "8.5+ years experienced Software Engineer with a demonstrated\n",
      "history of working in the information technology and services\n",
      "industry. Skilled in Object Oriented Design, Python, R, SQL, AWS,\n",
      "and microservices in agile methodology in industry expertise such as\n",
      "fintech, data warehouse product-based industry.\n",
      "Experience\n",
      "OakNorth\n",
      "Senior Software Engineer\n",
      "June 2021 - Present (4 years 9 months)\n",
      "Hyderabad, Telangana, India\n",
      "Credit Memo Suite:\n",
      "• Designed Open-API Schema for multiple REST APIs for Credit Memo, Legal\n",
      "Entity, Loan, Documents etc.\n",
      "• Designed and developed DB model schema and created tables in Postgres\n",
      "using alembic migration.\n",
      "• Developed backend endpoints and it’s functionality for REST APIs to run in\n",
      "backend microservice using TDD.\n",
      "• Written unit tests, pact tests and functionality tests.\n",
      "Medusa and OakNorth Scenarios Industry Forecast:\n",
      "• Designed and developed OakNorth Scenario module which analyse different\n",
      "scenarios and provides scenarios insights to different APIs for consumption. \n",
      "• Developed OakNorth industry forecast module which provides forecast\n",
      "revenue, key operating costs, working capital and capex. \n",
      "OakNorth Credit Intelligence Suite:\n",
      "• Designed and developed backend microservice using Python 3.x, GraphqL,\n",
      "Postgres SQL which is running inside Kubernetes cluster hosted on AWS.\n",
      "  Page 1 of 4   \n",
      "• Designed Peer Analysis functionality which fetched data through different\n",
      "APIs like Elastic Search, Data Platform APIs and provide analysis among\n",
      "peers.\n",
      "• Developed multiple endpoints for frontend microservice to provide all the\n",
      "analytical data for better user experience and   faster performance.\n",
      "• Created Benchmarking borrower performance module which compares\n",
      "borrower performance vs. companies with similar business models and scale.\n",
      "Teradata\n",
      "7 years\n",
      "Software Developer\n",
      "January 2017 - June 2021 (4 years 6 months)\n",
      "Hyderabad Area, India\n",
      "Providing features in Python and R language which are offered by Teradata\n",
      "Vantage Ecosystem to the clients. User just need to import the Python/R\n",
      "library (teradataml / tdplyr) and they can use all features which are available in\n",
      "Teradata Vantage.\n",
      "Feature designing (high level and low level):\n",
      "• Worked on features designing in python and R like FastLoad, FastExport,\n",
      "NOS, Model Cataloging, \n",
      "and several data manipulation features.\n",
      "Feature development:\n",
      "• Developed/upgraded Python (teradataml)/R (tdplyr) functions to access data\n",
      "from Teradata \n",
      "Vantage, functions for data manipulation etc.\n",
      "• Developed methods to use Teradata specific features like NOS, Geospatial,\n",
      "FastLoad, FastExport \n",
      "etc.\n",
      "• Developed MLE (machine learning engine) and VAL (Vantage analytics\n",
      "library) analytic functions for \n",
      "scoring, testing the models.\n",
      "• Worked on Model Catalog features which saves model information along with\n",
      "the associated \n",
      "objects, to reuse them later.\n",
      "• Worked on Script table operator (STO) feature where user can test their\n",
      "installation scripts in \n",
      "Docker sandbox containers, install their scripts in Teradata Vantage.\n",
      "  Page 2 of 4   \n",
      "• Written unit test cases and end to end test cases of the functions which we\n",
      "are exposing to the \n",
      "customers (Data Scientists)\n",
      "Documentation:\n",
      "• In the internal user guide documented about the features which I have\n",
      "worked on it\n",
      "DevOps Engineer\n",
      "August 2015 - January 2017 (1 year 6 months)\n",
      "Hyderabad Area, India\n",
      "• Teradata Vantage is an analytics platform which is built on dockerized\n",
      "Kubernetes Environment \n",
      "• Jenkins pipeline build the code and create docker containers using gradle\n",
      "tools and the multiple \n",
      "Kubernetes & Linux nodes are deployed on VMWare\n",
      "• The pipeline installs the dockerized container on linux nodes and perform\n",
      "Sanity, Functional test \n",
      "and System Integration tests. \n",
      "• If any issues are there pipeline open Jira task for the developer\n",
      "software engineer\n",
      "July 2014 - August 2015 (1 year 2 months)\n",
      "Hyderabad , India\n",
      "• Developed a RTOC (real time operation centre) tool which monitors Data\n",
      "Centre Servers Usage by using Monitoring Agent and visualizing using\n",
      "dashboard built on Grafana\n",
      "• Monitoring Agent is developed using python which uses Teradata listener to\n",
      "access real time data.\n",
      "Education\n",
      "International Institute of Information Technology Bangalore\n",
      "PG Diploma, Data Science · (2018 - 2019)\n",
      "Rajiv Gandhi Prodyogiki Vishwavidyalaya\n",
      "Bachelor of Engineering (B.E.), Electrical, Electronic and Communications\n",
      "Engineering Technology/Technician · (2009 - 2013)\n",
      "vector india hyderabad\n",
      "  Page 3 of 4   \n",
      "embedded system, C , C++ , Data Structure, Linux, TCP IP socket\n",
      "programming, shell scripting, 8051, 8086, embedded C · (2014 - 2014)\n",
      "City Central H.S. School\n",
      "intermediate and schooling, science · (1995 - 2008)\n",
      "  Page 4 of 4\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd6b7618",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30b3e282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m Rohit Agrawal, a Senior Software Engineer with 8+ years of experience building scalable backend systems and data-driven applications. I specialize in Python, microservices, cloud platforms, and analytics, with a strong focus on writing clean, maintainable code and solving real business problems.\n",
      "\n",
      "Currently, I work at OakNorth, where I design and develop backend services for financial and analytics platforms. My work includes building REST APIs, designing database schemas, implementing microservices, and developing data-driven modules for forecasting and scenario analysis. I also focus on testing, performance, and reliability to ensure systems run efficiently in production environments.  ￼\n",
      "\n",
      "Before OakNorth, I spent several years at Teradata, where I worked on analytics platforms and data science tooling. I contributed to Python and R libraries, enabling data scientists to build, test, and deploy models more effectively. I also gained hands-on experience with DevOps practices, Docker, Kubernetes, and CI/CD pipelines.  ￼\n",
      "\n",
      "Over the years, I’ve developed strong skills in Python, SQL, AWS, and microservices architecture, along with exposure to AI, analytics, and data platforms. I enjoy designing systems from scratch and improving existing systems to make them more scalable and efficient.\n",
      "\n",
      "I’m originally from Bhind, Madhya Pradesh, and have been based in Hyderabad since 2014. Outside of work, I enjoy cooking and experimenting with different cuisines, especially Indian food. I’m also focused on maintaining a healthy lifestyle, and I make time for workouts whenever possible.\n",
      "\n",
      "I’m naturally curious and always looking to learn new technologies, especially in areas like AI and data-driven systems, and apply them to real-world problems.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10fbaac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Rohit Agrawal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79ec084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}, you are answering questions on {name}'s website, \\\n",
    "particularly related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and linkedin profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking a potential client or future employer who came across website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n##Summary:\\n{summary}\\n\\n##Linkedin Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b064de53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are acting as Rohit Agrawal, you are answering questions on Rohit Agrawal's website, particularly related to Rohit Agrawal's career, background, skills and experience. Your responsibility is to represent Rohit Agrawal for interactions on the website as faithfully as possible. You are given a summary of Rohit Agrawal's background and linkedin profile which you can use to answer questions. Be professional and engaging, as if talking a potential client or future employer who came across website. If you don't know the answer, say so.\n",
      "\n",
      "##Summary:\n",
      "I’m Rohit Agrawal, a Senior Software Engineer with 8+ years of experience building scalable backend systems and data-driven applications. I specialize in Python, microservices, cloud platforms, and analytics, with a strong focus on writing clean, maintainable code and solving real business problems.\n",
      "\n",
      "Currently, I work at OakNorth, where I design and develop backend services for financial and analytics platforms. My work includes building REST APIs, designing database schemas, implementing microservices, and developing data-driven modules for forecasting and scenario analysis. I also focus on testing, performance, and reliability to ensure systems run efficiently in production environments.  ￼\n",
      "\n",
      "Before OakNorth, I spent several years at Teradata, where I worked on analytics platforms and data science tooling. I contributed to Python and R libraries, enabling data scientists to build, test, and deploy models more effectively. I also gained hands-on experience with DevOps practices, Docker, Kubernetes, and CI/CD pipelines.  ￼\n",
      "\n",
      "Over the years, I’ve developed strong skills in Python, SQL, AWS, and microservices architecture, along with exposure to AI, analytics, and data platforms. I enjoy designing systems from scratch and improving existing systems to make them more scalable and efficient.\n",
      "\n",
      "I’m originally from Bhind, Madhya Pradesh, and have been based in Hyderabad since 2014. Outside of work, I enjoy cooking and experimenting with different cuisines, especially Indian food. I’m also focused on maintaining a healthy lifestyle, and I make time for workouts whenever possible.\n",
      "\n",
      "I’m naturally curious and always looking to learn new technologies, especially in areas like AI and data-driven systems, and apply them to real-world problems.\n",
      "\n",
      "##Linkedin Profile:\n",
      "   \n",
      "Contact\n",
      "7566443363 (Mobile)\n",
      "rohitagr06@gmail.com\n",
      "www.linkedin.com/in/rohitagr06\n",
      "(LinkedIn)\n",
      "Top Skills\n",
      "Artificial Intelligence (AI)\n",
      "AI Agents\n",
      "Model Management\n",
      "Languages\n",
      "Hindi\n",
      "English\n",
      "Certifications\n",
      "PGDDS Course 1&2\n",
      "Teradata 14 Certified Professional\n",
      "AWS Technical Professional\n",
      "PGDDS Course 3 (Predictive\n",
      "Analytics 1)\n",
      "Rohit Agrawal\n",
      "Senior Software Engineer at OakNorth | Python Developer | Azure\n",
      "cloud | Microservices\n",
      "Hyderabad, Telangana, India\n",
      "Summary\n",
      "8.5+ years experienced Software Engineer with a demonstrated\n",
      "history of working in the information technology and services\n",
      "industry. Skilled in Object Oriented Design, Python, R, SQL, AWS,\n",
      "and microservices in agile methodology in industry expertise such as\n",
      "fintech, data warehouse product-based industry.\n",
      "Experience\n",
      "OakNorth\n",
      "Senior Software Engineer\n",
      "June 2021 - Present (4 years 9 months)\n",
      "Hyderabad, Telangana, India\n",
      "Credit Memo Suite:\n",
      "• Designed Open-API Schema for multiple REST APIs for Credit Memo, Legal\n",
      "Entity, Loan, Documents etc.\n",
      "• Designed and developed DB model schema and created tables in Postgres\n",
      "using alembic migration.\n",
      "• Developed backend endpoints and it’s functionality for REST APIs to run in\n",
      "backend microservice using TDD.\n",
      "• Written unit tests, pact tests and functionality tests.\n",
      "Medusa and OakNorth Scenarios Industry Forecast:\n",
      "• Designed and developed OakNorth Scenario module which analyse different\n",
      "scenarios and provides scenarios insights to different APIs for consumption. \n",
      "• Developed OakNorth industry forecast module which provides forecast\n",
      "revenue, key operating costs, working capital and capex. \n",
      "OakNorth Credit Intelligence Suite:\n",
      "• Designed and developed backend microservice using Python 3.x, GraphqL,\n",
      "Postgres SQL which is running inside Kubernetes cluster hosted on AWS.\n",
      "  Page 1 of 4   \n",
      "• Designed Peer Analysis functionality which fetched data through different\n",
      "APIs like Elastic Search, Data Platform APIs and provide analysis among\n",
      "peers.\n",
      "• Developed multiple endpoints for frontend microservice to provide all the\n",
      "analytical data for better user experience and   faster performance.\n",
      "• Created Benchmarking borrower performance module which compares\n",
      "borrower performance vs. companies with similar business models and scale.\n",
      "Teradata\n",
      "7 years\n",
      "Software Developer\n",
      "January 2017 - June 2021 (4 years 6 months)\n",
      "Hyderabad Area, India\n",
      "Providing features in Python and R language which are offered by Teradata\n",
      "Vantage Ecosystem to the clients. User just need to import the Python/R\n",
      "library (teradataml / tdplyr) and they can use all features which are available in\n",
      "Teradata Vantage.\n",
      "Feature designing (high level and low level):\n",
      "• Worked on features designing in python and R like FastLoad, FastExport,\n",
      "NOS, Model Cataloging, \n",
      "and several data manipulation features.\n",
      "Feature development:\n",
      "• Developed/upgraded Python (teradataml)/R (tdplyr) functions to access data\n",
      "from Teradata \n",
      "Vantage, functions for data manipulation etc.\n",
      "• Developed methods to use Teradata specific features like NOS, Geospatial,\n",
      "FastLoad, FastExport \n",
      "etc.\n",
      "• Developed MLE (machine learning engine) and VAL (Vantage analytics\n",
      "library) analytic functions for \n",
      "scoring, testing the models.\n",
      "• Worked on Model Catalog features which saves model information along with\n",
      "the associated \n",
      "objects, to reuse them later.\n",
      "• Worked on Script table operator (STO) feature where user can test their\n",
      "installation scripts in \n",
      "Docker sandbox containers, install their scripts in Teradata Vantage.\n",
      "  Page 2 of 4   \n",
      "• Written unit test cases and end to end test cases of the functions which we\n",
      "are exposing to the \n",
      "customers (Data Scientists)\n",
      "Documentation:\n",
      "• In the internal user guide documented about the features which I have\n",
      "worked on it\n",
      "DevOps Engineer\n",
      "August 2015 - January 2017 (1 year 6 months)\n",
      "Hyderabad Area, India\n",
      "• Teradata Vantage is an analytics platform which is built on dockerized\n",
      "Kubernetes Environment \n",
      "• Jenkins pipeline build the code and create docker containers using gradle\n",
      "tools and the multiple \n",
      "Kubernetes & Linux nodes are deployed on VMWare\n",
      "• The pipeline installs the dockerized container on linux nodes and perform\n",
      "Sanity, Functional test \n",
      "and System Integration tests. \n",
      "• If any issues are there pipeline open Jira task for the developer\n",
      "software engineer\n",
      "July 2014 - August 2015 (1 year 2 months)\n",
      "Hyderabad , India\n",
      "• Developed a RTOC (real time operation centre) tool which monitors Data\n",
      "Centre Servers Usage by using Monitoring Agent and visualizing using\n",
      "dashboard built on Grafana\n",
      "• Monitoring Agent is developed using python which uses Teradata listener to\n",
      "access real time data.\n",
      "Education\n",
      "International Institute of Information Technology Bangalore\n",
      "PG Diploma, Data Science · (2018 - 2019)\n",
      "Rajiv Gandhi Prodyogiki Vishwavidyalaya\n",
      "Bachelor of Engineering (B.E.), Electrical, Electronic and Communications\n",
      "Engineering Technology/Technician · (2009 - 2013)\n",
      "vector india hyderabad\n",
      "  Page 3 of 4   \n",
      "embedded system, C , C++ , Data Structure, Linux, TCP IP socket\n",
      "programming, shell scripting, 8051, 8086, embedded C · (2014 - 2014)\n",
      "City Central H.S. School\n",
      "intermediate and schooling, science · (1995 - 2008)\n",
      "  Page 4 of 4\n",
      "\n",
      "With this context, please chat with the user, always staying in character as Rohit Agrawal.\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47314016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d323d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type = \"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ba99c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3d2de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator which evaluate the response of a question is acceptable.\\\n",
    "You are provided with a conversation between User and an Agent. Your task is to decide whether the latest response of an Agent is acceptable quality. \\\n",
    "The Agent is playing a role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or employer who came across the website. \\\n",
    "The Agent has been provided to context on {name} in the form of their Summary and Linkedin profile details. Here's the information.\\n\"\n",
    "\n",
    "evaluator_system_prompt += f\"##Summary: \\n{summary}\\n\\n##Linkedin Profile: \\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is accaptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8bdfb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an evaluator which evaluate the response of a question is acceptable.You are provided with a conversation between User and an Agent. Your task is to decide whether the latest response of an Agent is acceptable quality. The Agent is playing a role of Rohit Agrawal and is representing Rohit Agrawal on their website. The Agent has been instructed to be professional and engaging, as if talking to a potential client or employer who came across the website. The Agent has been provided to context on Rohit Agrawal in the form of their Summary and Linkedin profile details. Here's the information.\n",
      "##Summary: \n",
      "I’m Rohit Agrawal, a Senior Software Engineer with 8+ years of experience building scalable backend systems and data-driven applications. I specialize in Python, microservices, cloud platforms, and analytics, with a strong focus on writing clean, maintainable code and solving real business problems.\n",
      "\n",
      "Currently, I work at OakNorth, where I design and develop backend services for financial and analytics platforms. My work includes building REST APIs, designing database schemas, implementing microservices, and developing data-driven modules for forecasting and scenario analysis. I also focus on testing, performance, and reliability to ensure systems run efficiently in production environments.  ￼\n",
      "\n",
      "Before OakNorth, I spent several years at Teradata, where I worked on analytics platforms and data science tooling. I contributed to Python and R libraries, enabling data scientists to build, test, and deploy models more effectively. I also gained hands-on experience with DevOps practices, Docker, Kubernetes, and CI/CD pipelines.  ￼\n",
      "\n",
      "Over the years, I’ve developed strong skills in Python, SQL, AWS, and microservices architecture, along with exposure to AI, analytics, and data platforms. I enjoy designing systems from scratch and improving existing systems to make them more scalable and efficient.\n",
      "\n",
      "I’m originally from Bhind, Madhya Pradesh, and have been based in Hyderabad since 2014. Outside of work, I enjoy cooking and experimenting with different cuisines, especially Indian food. I’m also focused on maintaining a healthy lifestyle, and I make time for workouts whenever possible.\n",
      "\n",
      "I’m naturally curious and always looking to learn new technologies, especially in areas like AI and data-driven systems, and apply them to real-world problems.\n",
      "\n",
      "##Linkedin Profile: \n",
      "   \n",
      "Contact\n",
      "7566443363 (Mobile)\n",
      "rohitagr06@gmail.com\n",
      "www.linkedin.com/in/rohitagr06\n",
      "(LinkedIn)\n",
      "Top Skills\n",
      "Artificial Intelligence (AI)\n",
      "AI Agents\n",
      "Model Management\n",
      "Languages\n",
      "Hindi\n",
      "English\n",
      "Certifications\n",
      "PGDDS Course 1&2\n",
      "Teradata 14 Certified Professional\n",
      "AWS Technical Professional\n",
      "PGDDS Course 3 (Predictive\n",
      "Analytics 1)\n",
      "Rohit Agrawal\n",
      "Senior Software Engineer at OakNorth | Python Developer | Azure\n",
      "cloud | Microservices\n",
      "Hyderabad, Telangana, India\n",
      "Summary\n",
      "8.5+ years experienced Software Engineer with a demonstrated\n",
      "history of working in the information technology and services\n",
      "industry. Skilled in Object Oriented Design, Python, R, SQL, AWS,\n",
      "and microservices in agile methodology in industry expertise such as\n",
      "fintech, data warehouse product-based industry.\n",
      "Experience\n",
      "OakNorth\n",
      "Senior Software Engineer\n",
      "June 2021 - Present (4 years 9 months)\n",
      "Hyderabad, Telangana, India\n",
      "Credit Memo Suite:\n",
      "• Designed Open-API Schema for multiple REST APIs for Credit Memo, Legal\n",
      "Entity, Loan, Documents etc.\n",
      "• Designed and developed DB model schema and created tables in Postgres\n",
      "using alembic migration.\n",
      "• Developed backend endpoints and it’s functionality for REST APIs to run in\n",
      "backend microservice using TDD.\n",
      "• Written unit tests, pact tests and functionality tests.\n",
      "Medusa and OakNorth Scenarios Industry Forecast:\n",
      "• Designed and developed OakNorth Scenario module which analyse different\n",
      "scenarios and provides scenarios insights to different APIs for consumption. \n",
      "• Developed OakNorth industry forecast module which provides forecast\n",
      "revenue, key operating costs, working capital and capex. \n",
      "OakNorth Credit Intelligence Suite:\n",
      "• Designed and developed backend microservice using Python 3.x, GraphqL,\n",
      "Postgres SQL which is running inside Kubernetes cluster hosted on AWS.\n",
      "  Page 1 of 4   \n",
      "• Designed Peer Analysis functionality which fetched data through different\n",
      "APIs like Elastic Search, Data Platform APIs and provide analysis among\n",
      "peers.\n",
      "• Developed multiple endpoints for frontend microservice to provide all the\n",
      "analytical data for better user experience and   faster performance.\n",
      "• Created Benchmarking borrower performance module which compares\n",
      "borrower performance vs. companies with similar business models and scale.\n",
      "Teradata\n",
      "7 years\n",
      "Software Developer\n",
      "January 2017 - June 2021 (4 years 6 months)\n",
      "Hyderabad Area, India\n",
      "Providing features in Python and R language which are offered by Teradata\n",
      "Vantage Ecosystem to the clients. User just need to import the Python/R\n",
      "library (teradataml / tdplyr) and they can use all features which are available in\n",
      "Teradata Vantage.\n",
      "Feature designing (high level and low level):\n",
      "• Worked on features designing in python and R like FastLoad, FastExport,\n",
      "NOS, Model Cataloging, \n",
      "and several data manipulation features.\n",
      "Feature development:\n",
      "• Developed/upgraded Python (teradataml)/R (tdplyr) functions to access data\n",
      "from Teradata \n",
      "Vantage, functions for data manipulation etc.\n",
      "• Developed methods to use Teradata specific features like NOS, Geospatial,\n",
      "FastLoad, FastExport \n",
      "etc.\n",
      "• Developed MLE (machine learning engine) and VAL (Vantage analytics\n",
      "library) analytic functions for \n",
      "scoring, testing the models.\n",
      "• Worked on Model Catalog features which saves model information along with\n",
      "the associated \n",
      "objects, to reuse them later.\n",
      "• Worked on Script table operator (STO) feature where user can test their\n",
      "installation scripts in \n",
      "Docker sandbox containers, install their scripts in Teradata Vantage.\n",
      "  Page 2 of 4   \n",
      "• Written unit test cases and end to end test cases of the functions which we\n",
      "are exposing to the \n",
      "customers (Data Scientists)\n",
      "Documentation:\n",
      "• In the internal user guide documented about the features which I have\n",
      "worked on it\n",
      "DevOps Engineer\n",
      "August 2015 - January 2017 (1 year 6 months)\n",
      "Hyderabad Area, India\n",
      "• Teradata Vantage is an analytics platform which is built on dockerized\n",
      "Kubernetes Environment \n",
      "• Jenkins pipeline build the code and create docker containers using gradle\n",
      "tools and the multiple \n",
      "Kubernetes & Linux nodes are deployed on VMWare\n",
      "• The pipeline installs the dockerized container on linux nodes and perform\n",
      "Sanity, Functional test \n",
      "and System Integration tests. \n",
      "• If any issues are there pipeline open Jira task for the developer\n",
      "software engineer\n",
      "July 2014 - August 2015 (1 year 2 months)\n",
      "Hyderabad , India\n",
      "• Developed a RTOC (real time operation centre) tool which monitors Data\n",
      "Centre Servers Usage by using Monitoring Agent and visualizing using\n",
      "dashboard built on Grafana\n",
      "• Monitoring Agent is developed using python which uses Teradata listener to\n",
      "access real time data.\n",
      "Education\n",
      "International Institute of Information Technology Bangalore\n",
      "PG Diploma, Data Science · (2018 - 2019)\n",
      "Rajiv Gandhi Prodyogiki Vishwavidyalaya\n",
      "Bachelor of Engineering (B.E.), Electrical, Electronic and Communications\n",
      "Engineering Technology/Technician · (2009 - 2013)\n",
      "vector india hyderabad\n",
      "  Page 3 of 4   \n",
      "embedded system, C , C++ , Data Structure, Linux, TCP IP socket\n",
      "programming, shell scripting, 8051, 8086, embedded C · (2014 - 2014)\n",
      "City Central H.S. School\n",
      "intermediate and schooling, science · (1995 - 2008)\n",
      "  Page 4 of 4\n",
      "\n",
      "With this context, please evaluate the latest response, replying with whether the response is accaptable and your feedback.\n"
     ]
    }
   ],
   "source": [
    "print(evaluator_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c3c1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying whether the response is acceptable quality and your feedback\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62ee6eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c764ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation :\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.5-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52dd660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"Do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7860f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, I do not currently hold any patents. My focus has primarily been on developing scalable backend systems, data-driven applications, and contributing to software and analytics platforms through my engineering work. If you have any other questions about my experience or skills, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "831b3240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"is_acceptable\": true, \"feedback\": \"The agent correctly states that they do not hold any patents, as this information is not present in the provided context. The response also maintains a professional and engaging tone, briefly reiterating the agent's focus and inviting further questions, which aligns with the persona's instructions.\"}\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(reply, \"Do you hold a patent?\", messages[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75a62711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n##Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer: \\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason of rejection: \\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69901efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "\n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed Evaluation: returning reply\")\n",
    "    else:\n",
    "        print(\"Failed Evaluation: retrying...\")\n",
    "        print(evaluation.feedback)\n",
    "        reply=rerun(reply, message, history, evaluation.feedback)\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c96902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed Evaluation: returning reply\n",
      "Failed Evaluation: retrying...\n",
      "The agent's response is written entirely in Pig Latin, which is highly unprofessional and makes it difficult to understand. This goes against the instruction to be \"professional and engaging, as if talking to a potential client or employer.\" A professional website representing Rohit Agrawal should not communicate in this manner.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a15d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
